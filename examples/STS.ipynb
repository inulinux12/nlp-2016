{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Graphics Device (CNMeM is disabled, CuDNN 3007)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model_path = \"/home/datasets/datasets1/word2vec-embeddings/GoogleNews-vectors-negative300.bin.gz\"\n",
    "model_word2vec = Word2Vec.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "datasets_file = sorted(glob.glob(\"dataset_texsim/*.input.*\"))\n",
    "gold_standard_file = sorted(glob.glob(\"dataset_texsim/*.gs.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_dataset(filename_input, gs_file):\n",
    "    with open(filename_input, \"r\") as f:\n",
    "        input_pair = [x.split(\"\\t\") for x in f.read().splitlines()]\n",
    "    with open(gs_file, \"r\") as f:\n",
    "        input_gs = [float(x) for x in f.read().splitlines()]\n",
    "    return input_pair, input_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_sim_monge(sen1, sen2, p, lex_sim_fun):\n",
    "    #tokenizing here\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words_sen1 = tokenizer.tokenize(sen1)\n",
    "    words_sen2 = tokenizer.tokenize(sen2)\n",
    "    word_sim = []\n",
    "    for word1 in words_sen1:\n",
    "        word_sim.append([lex_sim_fun(model_word2vec, word1, word2) for word2 in words_sen2])\n",
    "    word_sim = np.array(word_sim)\n",
    "    return np.sum([np.power(np.max(x), p) for x in word_sim])/len(words_sen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lex_sim_w2v(model, word1, word2):\n",
    "    #model has to be gensim's model\n",
    "    if (word1 in model_word2vec.vocab) and (word2 in model_word2vec.vocab):\n",
    "        return model_word2vec.similarity(word1, word2)\n",
    "    else:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs, gs = read_dataset(datasets_file[1], gold_standard_file[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_sim = []\n",
    "for word1 in tokenizer.tokenize(pairs[1][0]):\n",
    "    word_sim.append([lex_sim_w2v(model_word2vec, word1, word2) for word2 in tokenizer.tokenize(pairs[1][1])])\n",
    "word_sim = np.array(word_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68358763,  0.04238769,  0.07125915,  0.19398442,  0.0467174 ,\n",
       "         0.09638663],\n",
       "       [ 0.06270984,  0.32290686,  1.        ,  0.04031163,  0.0612379 ,\n",
       "         0.0902412 ],\n",
       "       [ 0.2028677 ,  0.01897395,  0.04031163,  1.        ,  0.09532947,\n",
       "         0.05088437],\n",
       "       [ 0.02006767,  0.04898579,  0.0612379 ,  0.09532947,  1.        ,\n",
       "         0.13625418],\n",
       "       [-0.0399349 ,  0.10082886,  0.0902412 ,  0.05088437,  0.13625418,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68358763,  1.        ,  1.        ,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(word_sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dataset_texsim/2012.input.MSRpar.txt', 750, 0.43385402711875631)\n",
      "('dataset_texsim/2012.input.MSRvid.txt', 750, 0.42962853892838276)\n",
      "('dataset_texsim/2012.input.OnWN.txt', 750, 0.52360912174631069)\n",
      "('dataset_texsim/2012.input.SMTeuroparl.txt', 459, 0.38817345996370839)\n",
      "('dataset_texsim/2012.input.SMTnews.txt', 399, 0.45451554573392566)\n",
      "('dataset_texsim/2013.input.FNWN.txt', 189, 0.34788248671992644)\n",
      "('dataset_texsim/2013.input.OnWN.txt', 561, 0.47859521829926593)\n",
      "('dataset_texsim/2013.input.SMT.txt', 750, nan)\n",
      "('dataset_texsim/2013.input.headlines.txt', 750, 0.58882688783521342)\n",
      "('dataset_texsim/2014.input.OnWN.txt', 750, 0.5769935586146)\n",
      "('dataset_texsim/2014.input.deft-forum.txt', 450, 0.3530931258566975)\n",
      "('dataset_texsim/2014.input.deft-news.txt', 300, 0.50566661482529607)\n",
      "('dataset_texsim/2014.input.headlines.txt', 750, 0.57220288208569359)\n",
      "('dataset_texsim/2014.input.images.txt', 750, 0.54444668618352487)\n",
      "('dataset_texsim/2014.input.tweet-news.txt', 750, 0.68361677643476682)\n",
      "('dataset_texsim/2015.input.answers-forums.txt', 375, 0.48114000242778587)\n",
      "('dataset_texsim/2015.input.answers-students.txt', 750, 0.55028019413797724)\n",
      "('dataset_texsim/2015.input.belief.txt', 375, 0.62610141916281226)\n",
      "('dataset_texsim/2015.input.headlines.txt', 750, 0.61104240615866701)\n",
      "('dataset_texsim/2015.input.images.txt', 750, 0.626311622322415)\n",
      "('dataset_texsim/2016.input.answer-answer.txt', 254, 0.3590792507596921)\n",
      "('dataset_texsim/2016.input.headlines.txt', 249, 0.60267817808045698)\n",
      "('dataset_texsim/2016.input.plagiarism.txt', 230, 0.66828540577099249)\n",
      "('dataset_texsim/2016.input.postediting.txt', 244, 0.73076785835265845)\n",
      "('dataset_texsim/2016.input.question-question.txt', 209, 0.3770869151533871)\n"
     ]
    }
   ],
   "source": [
    "for dataset, gs_file in zip(datasets_file, gold_standard_file):\n",
    "    pairs, gs = read_dataset(dataset, gs_file)\n",
    "    predictions = [text_sim_monge(sen1, sen2, 1, lex_sim_w2v) for sen1, sen2 in pairs]\n",
    "    pearson = pearsonr(gs, predictions)[0]\n",
    "    print(dataset, len(pairs), pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dataset_texsim/2012.input.MSRpar.txt', 750, 0.43882435929567665)\n",
      "('dataset_texsim/2012.input.MSRvid.txt', 750, 0.410555272976737)\n",
      "('dataset_texsim/2012.input.OnWN.txt', 750, 0.5489341680335138)\n",
      "('dataset_texsim/2012.input.SMTeuroparl.txt', 459, 0.42874884686381221)\n",
      "('dataset_texsim/2012.input.SMTnews.txt', 399, 0.44691726842112972)\n",
      "('dataset_texsim/2013.input.FNWN.txt', 189, 0.32872815806656769)\n",
      "('dataset_texsim/2013.input.OnWN.txt', 561, 0.47554178204642367)\n",
      "('dataset_texsim/2013.input.SMT.txt', 750, nan)\n",
      "('dataset_texsim/2013.input.headlines.txt', 750, 0.58759594159991657)\n",
      "('dataset_texsim/2014.input.OnWN.txt', 750, 0.57854622239888143)\n",
      "('dataset_texsim/2014.input.deft-forum.txt', 450, 0.38361484062488593)\n",
      "('dataset_texsim/2014.input.deft-news.txt', 300, 0.52682536680896697)\n",
      "('dataset_texsim/2014.input.headlines.txt', 750, 0.56352898025159037)\n",
      "('dataset_texsim/2014.input.images.txt', 750, 0.56453560076683906)\n",
      "('dataset_texsim/2014.input.tweet-news.txt', 750, 0.69101209430436594)\n",
      "('dataset_texsim/2015.input.answers-forums.txt', 375, 0.50725717960841643)\n",
      "('dataset_texsim/2015.input.answers-students.txt', 750, 0.58295603390492534)\n",
      "('dataset_texsim/2015.input.belief.txt', 375, 0.64879152373933813)\n",
      "('dataset_texsim/2015.input.headlines.txt', 750, 0.59432898442226922)\n",
      "('dataset_texsim/2015.input.images.txt', 750, 0.64517928129402446)\n",
      "('dataset_texsim/2016.input.answer-answer.txt', 254, 0.36189507612373578)\n",
      "('dataset_texsim/2016.input.headlines.txt', 249, 0.58766071088996175)\n",
      "('dataset_texsim/2016.input.plagiarism.txt', 230, 0.69889926289470705)\n",
      "('dataset_texsim/2016.input.postediting.txt', 244, 0.77884756237777608)\n",
      "('dataset_texsim/2016.input.question-question.txt', 209, 0.33067789316150759)\n"
     ]
    }
   ],
   "source": [
    "for dataset, gs_file in zip(datasets_file, gold_standard_file):\n",
    "    pairs, gs = read_dataset(dataset, gs_file)\n",
    "    predictions = [text_sim_monge(sen1, sen2, 2, lex_sim_w2v) for sen1, sen2 in pairs]\n",
    "    pearson = pearsonr(gs, predictions)[0]\n",
    "    print(dataset, len(pairs), pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs, gs = read_dataset(datasets_file[7], gold_standard_file[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_texsim/2013.input.SMT.txt\n"
     ]
    }
   ],
   "source": [
    "print(datasets_file[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [text_sim_monge(sen1, sen2, 1, lex_sim_w2v) for sen1, sen2 in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.58943237054898345,\n",
       " 0.58011762621832597,\n",
       " 0.59917285183169122,\n",
       " 0.58721392656339944,\n",
       " 0.52732752380663561,\n",
       " 0.79622809019442664,\n",
       " 0.7487018586240628,\n",
       " 0.72811581018397908,\n",
       " 0.55452763110386549,\n",
       " 0.57320228291263375,\n",
       " 0.77757053531232667,\n",
       " 0.52260266686092194,\n",
       " 0.37993436622026172,\n",
       " 0.36370340390152806,\n",
       " 0.5320864138882847,\n",
       " 0.60373193877978237,\n",
       " 0.52761665306261762,\n",
       " 0.62529684007609454,\n",
       " 0.68641834583428063,\n",
       " 0.48735298963869611,\n",
       " 0.94901290276161354,\n",
       " 0.43840244454876193,\n",
       " 0.55306041376156223,\n",
       " 0.62999585904785282,\n",
       " 0.98522329158102473,\n",
       " 0.57164706933350051,\n",
       " 0.56165512725574041,\n",
       " 0.48099564533249423,\n",
       " 0.52334451174703056,\n",
       " 0.60145744238910825,\n",
       " 0.44893259707233779,\n",
       " 0.57508329575033823,\n",
       " 0.53006768799715709,\n",
       " 0.59285935723509497,\n",
       " 0.72367731552933867,\n",
       " 0.49102386692168759,\n",
       " 0.89285119716825001,\n",
       " 0.76860661474341274,\n",
       " 0.59643969045425616,\n",
       " 0.29906058352935333,\n",
       " 0.34081627981141283,\n",
       " 0.52676575753491006,\n",
       " 0.5389769277459816,\n",
       " 0.63132544280446734,\n",
       " 0.47046017899923931,\n",
       " 0.49052727355682224,\n",
       " 0.6371123350886343,\n",
       " 0.62047051741459047,\n",
       " 0.45519870209711205,\n",
       " 0.69983029231045413,\n",
       " 0.81863144208755945,\n",
       " 0.42781938923666613,\n",
       " 0.52180198766028163,\n",
       " 0.80038606810677615,\n",
       " 0.59757326622635443,\n",
       " 0.41460888254337319,\n",
       " 0.68140884151080972,\n",
       " 0.36257140935571075,\n",
       " 1.0,\n",
       " 0.8429421951192535,\n",
       " 0.50586814097159705,\n",
       " 0.54760267845535038,\n",
       " 0.85975982535273709,\n",
       " 0.86800727058713756,\n",
       " 0.42587965791833149,\n",
       " 0.55895211437877867,\n",
       " 0.57320336372252367,\n",
       " 0.82501810720545266,\n",
       " 0.6072045192817096,\n",
       " 0.60670872357735639,\n",
       " 0.32516310388222347,\n",
       " 0.55496360838004799,\n",
       " 0.53787943841114971,\n",
       " 0.48326843331862174,\n",
       " 0.42283572023211996,\n",
       " 0.55604377833382257,\n",
       " 0.56578380655760896,\n",
       " 0.46263590009758532,\n",
       " 0.45252194403717599,\n",
       " 0.42343080415043077,\n",
       " 0.84353120849403329,\n",
       " 0.61533533080721425,\n",
       " 0.79763134010384418,\n",
       " 0.63368502901071488,\n",
       " 0.47700065571436545,\n",
       " 0.83676325755983039,\n",
       " 0.68324151879551809,\n",
       " 0.60678278610716052,\n",
       " 0.69317960250786992,\n",
       " 0.68083179567303653,\n",
       " 0.47343667343717127,\n",
       " 0.67096663525502365,\n",
       " 0.56930083637371609,\n",
       " 0.54842725202665055,\n",
       " 0.71052564866689716,\n",
       " 0.68371247312146155,\n",
       " 0.85714285714285732,\n",
       " 0.67576066978833016,\n",
       " 0.70844813487846559,\n",
       " 0.48170445528513584,\n",
       " 0.86746750379655069,\n",
       " 0.65853560304343883,\n",
       " 0.71080154257249206,\n",
       " 0.80809904579816449,\n",
       " 0.4263104725415458,\n",
       " 0.61260163640654475,\n",
       " 0.56643988613246277,\n",
       " 0.91821080567487434,\n",
       " 0.51123254300964993,\n",
       " 0.84350016936585104,\n",
       " 0.62273939745133311,\n",
       " 0.73329980599685096,\n",
       " 0.42809976810935541,\n",
       " 0.6902485488467176,\n",
       " 0.40712873987275988,\n",
       " 0.47180462566334458,\n",
       " 0.52710289269954302,\n",
       " 0.55221124711804448,\n",
       " 0.89870567134783341,\n",
       " 0.52596724131433692,\n",
       " 0.54924765671669817,\n",
       " 0.58778229796164472,\n",
       " 0.68675253216056631,\n",
       " 0.51867159494170445,\n",
       " 0.58547314206207701,\n",
       " 0.92307692307692313,\n",
       " 0.7573334498132126,\n",
       " 0.83870444841138414,\n",
       " 0.8760206156192657,\n",
       " 0.71304926482954278,\n",
       " 0.51097880257972017,\n",
       " 0.46178344903825252,\n",
       " 0.61605437049654665,\n",
       " 0.5072853426446341,\n",
       " 0.59514584835335915,\n",
       " 0.49320258709273945,\n",
       " 0.79589820359079289,\n",
       " 0.82542173520547246,\n",
       " 0.66428796561473458,\n",
       " 0.54388482574554453,\n",
       " 0.44182826124991276,\n",
       " 0.44233598259742951,\n",
       " 0.56850272650171663,\n",
       " 0.56545415379600583,\n",
       " 0.4786895448909585,\n",
       " 0.79001120519808088,\n",
       " 0.69955004702535573,\n",
       " 0.62858368666268971,\n",
       " 0.65319508743037569,\n",
       " 0.40181149256056958,\n",
       " 0.59988567494825051,\n",
       " 0.43156654165130831,\n",
       " 0.5311069887321852,\n",
       " 0.58679754005177842,\n",
       " 0.64108567067768718,\n",
       " 0.53355830909357416,\n",
       " 0.48627759212022637,\n",
       " 0.60933588020520402,\n",
       " 0.39605647663372556,\n",
       " 0.90000000000000002,\n",
       " 0.52960844026208109,\n",
       " 0.52908350561033202,\n",
       " 0.70600503160697226,\n",
       " 0.58554775512447776,\n",
       " 0.74563020106698641,\n",
       " 0.60224970986170667,\n",
       " 0.71581590336784173,\n",
       " 0.61242527197866703,\n",
       " 0.42730706378821176,\n",
       " 0.62563394184492482,\n",
       " 0.5977240299496045,\n",
       " 0.65070870452801388,\n",
       " 0.66799780516416418,\n",
       " 0.59120747686674757,\n",
       " 0.74453308785516914,\n",
       " 0.34182710311106085,\n",
       " 0.7041181703944408,\n",
       " 0.486851760755595,\n",
       " 0.44395793417292001,\n",
       " 0.64214578375821552,\n",
       " 0.6413618976133566,\n",
       " 0.6113393493616136,\n",
       " 0.80615985825198389,\n",
       " 0.65060157233347216,\n",
       " 0.55280075323408551,\n",
       " 0.75645385344891558,\n",
       " 0.85782151071797585,\n",
       " 0.64111388307328065,\n",
       " 0.68358557606534243,\n",
       " 0.60178035594285917,\n",
       " 0.68865139002197362,\n",
       " 0.7056467145209776,\n",
       " 0.50559071679486967,\n",
       " 0.60746317407631567,\n",
       " 0.69295573875912664,\n",
       " 0.55274523677510223,\n",
       " 0.48845576009815145,\n",
       " 0.33981535491470838,\n",
       " 0.59647438332785774,\n",
       " 0.52544669418826495,\n",
       " 0.42766036153528014,\n",
       " 0.76350801396630397,\n",
       " 0.5930514085380526,\n",
       " 0.38675855533834225,\n",
       " 0.680498476761353,\n",
       " 0.47966947516892228,\n",
       " 0.67703516404075426,\n",
       " 0.56703754770464254,\n",
       " 0.56632016430745458,\n",
       " 0.68236885823240612,\n",
       " 0.87940350953801305,\n",
       " 0.4037452963098373,\n",
       " 0.706911836836012,\n",
       " 0.53595545353209462,\n",
       " 0.6032990703504395,\n",
       " 0.62064442713532086,\n",
       " 0.89526624278300937,\n",
       " 0.94444444444444442,\n",
       " 0.66160187659077196,\n",
       " 0.55230309531203559,\n",
       " 0.67471938029622658,\n",
       " 0.43192667560069192,\n",
       " 0.85405960153263849,\n",
       " 0.56593742335178832,\n",
       " 0.53932906871042863,\n",
       " 0.86214294118265744,\n",
       " 0.84030356733549194,\n",
       " 0.61969576612395405,\n",
       " 0.53355374306889036,\n",
       " 0.69498127433783352,\n",
       " 0.52762151841601934,\n",
       " 0.65384873430164725,\n",
       " 0.45853852643422777,\n",
       " 0.71314861623289039,\n",
       " 0.50468658109576292,\n",
       " 0.80000000000000004,\n",
       " 0.59849814964798442,\n",
       " 0.44439400475673946,\n",
       " 0.52411216239490266,\n",
       " 0.51155149411938816,\n",
       " 0.50280176400021181,\n",
       " 0.6840823753144627,\n",
       " 0.70179057093196051,\n",
       " 0.48850540350384924,\n",
       " 0.74535911543329536,\n",
       " 0.59433041904324635,\n",
       " 0.89484332164467018,\n",
       " 0.59688179512496331,\n",
       " 0.54420987692616007,\n",
       " 0.47864560387708005,\n",
       " 0.71309400756846864,\n",
       " 0.59626293308689438,\n",
       " 0.3954686148329401,\n",
       " 0.68630243868434748,\n",
       " 0.4996568523724253,\n",
       " 0.6276431171536242,\n",
       " 0.60210155467038051,\n",
       " 0.37951519107310211,\n",
       " 0.8571428571428571,\n",
       " 0.81675065032093674,\n",
       " 0.47311780840656553,\n",
       " 0.51356994408045664,\n",
       " 0.56219275123719492,\n",
       " 0.59480194999037816,\n",
       " 0.53880501166866246,\n",
       " 0.56388941394216563,\n",
       " 1.0,\n",
       " 0.52636354511231376,\n",
       " 0.521771491459746,\n",
       " 0.74247246845129111,\n",
       " 0.53924250177970334,\n",
       " 0.6334541730028771,\n",
       " 0.65818963683529141,\n",
       " 0.65621022347536195,\n",
       " 0.57418909007221519,\n",
       " 0.48785189684140462,\n",
       " 0.76523294873981507,\n",
       " 0.37679433081751229,\n",
       " 0.54380671277494119,\n",
       " 0.61960076246180562,\n",
       " 0.51733721348228334,\n",
       " 0.60522764138800955,\n",
       " 0.6840972463831626,\n",
       " 0.88452441754187772,\n",
       " 0.71935182630547634,\n",
       " 0.83333333333333337,\n",
       " 0.41916393245152472,\n",
       " 0.69865065597815468,\n",
       " 0.56192721371168575,\n",
       " 0.53151512631302977,\n",
       " 0.57252250256771642,\n",
       " 0.52983703228905554,\n",
       " 0.55578478881317483,\n",
       " 0.52925313386587347,\n",
       " 0.65513498198374798,\n",
       " 0.56444652331787171,\n",
       " 0.5977339263511986,\n",
       " 0.75131136331419823,\n",
       " 0.40441929810748972,\n",
       " 0.68686799136502352,\n",
       " 0.62769036564596492,\n",
       " 0.68234484361984127,\n",
       " 0.5419187544452122,\n",
       " 0.54103698022495728,\n",
       " 0.73890282920031103,\n",
       " 0.78044417975495928,\n",
       " 0.53345340137910102,\n",
       " 0.88221986587543966,\n",
       " 0.63722528023022074,\n",
       " 0.38885679097256959,\n",
       " 0.43839805873166221,\n",
       " 0.52804717044972294,\n",
       " 0.41900279789897066,\n",
       " 0.70556729758058623,\n",
       " 0.77370914345070851,\n",
       " 0.62548348227444939,\n",
       " 0.45944601256451428,\n",
       " 0.70465768898269943,\n",
       " 0.51457133969092239,\n",
       " 0.81103429018562889,\n",
       " 0.63136105866767156,\n",
       " 0.60703456591551197,\n",
       " 0.31424973321165278,\n",
       " 0,\n",
       " 0.53416039566612028,\n",
       " 0.77941966436519505,\n",
       " 0.91304347826086951,\n",
       " 0.92307692307692313,\n",
       " 0.52574831344722006,\n",
       " 0.61035822235930615,\n",
       " 0.61123389490999602,\n",
       " 0.4848919901854446,\n",
       " 0.86822923115185635,\n",
       " 0.76384697156653869,\n",
       " 0.50659267950134612,\n",
       " 0.94360835683266175,\n",
       " 0.61881441130195025,\n",
       " 0.62039926256554345,\n",
       " 0.59183966301444746,\n",
       " 0.75630415623194724,\n",
       " 0.66424400471136458,\n",
       " 0.6630348251103837,\n",
       " 0.63889597219726491,\n",
       " 0.66026256775592373,\n",
       " 0.39942641095780529,\n",
       " 0.47498485626389203,\n",
       " 0.67024812852485116,\n",
       " 0.55679583509957065,\n",
       " 0.58624079637070914,\n",
       " 0.77602140065701286,\n",
       " 0.49214347560726918,\n",
       " 0.57696395862639427,\n",
       " 0.50004749727276754,\n",
       " 0.91575915719643897,\n",
       " 0.65949250401702075,\n",
       " 0.58143811206138096,\n",
       " 0.42330073373031707,\n",
       " 0.40609650859145263,\n",
       " 0.70343913253988855,\n",
       " 0.41760310102458065,\n",
       " 0.70189310168160957,\n",
       " 0.72994049473395983,\n",
       " 0.59583762955038455,\n",
       " 0.54678777746623153,\n",
       " 0.66757469518852641,\n",
       " 0.90947462948057789,\n",
       " 0.58465801479276247,\n",
       " 0.46353787640722327,\n",
       " 0.64819099557444271,\n",
       " 0.45211167114618905,\n",
       " 1.0000000000000002,\n",
       " 0.55052126042433491,\n",
       " 0.74264665828963627,\n",
       " 0.54575653209700892,\n",
       " 0.54908618192674119,\n",
       " 0.5785420188029109,\n",
       " 0.48925990502016165,\n",
       " 0.56972683742219976,\n",
       " 0.49866655533062126,\n",
       " 0.45509639939787355,\n",
       " 0.66182079835829977,\n",
       " 0.57758128116078811,\n",
       " 0.5066257340493191,\n",
       " 0.47289930088728543,\n",
       " 1.0,\n",
       " 0.48670608691044026,\n",
       " 0.32149144296437754,\n",
       " 0.54897183499299251,\n",
       " 0.8596843787836469,\n",
       " 0.6369529107505193,\n",
       " 0.47655177966434731,\n",
       " 1.0,\n",
       " 0.50484236291816753,\n",
       " 0.62696244750742891,\n",
       " 0.47147415957235539,\n",
       " 0.60804660312376735,\n",
       " 0.57145019628932991,\n",
       " 0.82171648934102259,\n",
       " 0.45203752504592787,\n",
       " 0.77942994673356769,\n",
       " 0.81300170372521186,\n",
       " 0.42247993004024953,\n",
       " 0.79489607298281262,\n",
       " 0.54159686779365712,\n",
       " 0.82400001048566685,\n",
       " 0.65605159218962494,\n",
       " 0.57015062039686082,\n",
       " 0.52474342297347243,\n",
       " 0.64224329712311323,\n",
       " 0.5703041866516072,\n",
       " 0.52239165402404431,\n",
       " 0.55775163638300818,\n",
       " 0.59397836908401203,\n",
       " 0.61712326520333327,\n",
       " 0.61328620278089252,\n",
       " 0.60296367148314978,\n",
       " 0.52562676505146122,\n",
       " 0.88888888888888884,\n",
       " 0.58363048365203596,\n",
       " nan,\n",
       " 0.56889037142592458,\n",
       " 0.62671369337453242,\n",
       " 0.59706909179554535,\n",
       " 0.62099451869770372,\n",
       " 0.72013746684762814,\n",
       " 0.57314564322896289,\n",
       " 0.51810481049008894,\n",
       " 0.57829988258343912,\n",
       " 0.68387497675400621,\n",
       " 0.80618162615750211,\n",
       " 0.70874832653205977,\n",
       " 0.60872504213337242,\n",
       " 0.62653883214026429,\n",
       " 0.83370845145992767,\n",
       " 0.28286485116237803,\n",
       " 0.56815451481830637,\n",
       " 0.56939192273550709,\n",
       " 0.52618905629094315,\n",
       " 0.63584178019651583,\n",
       " 0.72724115695885538,\n",
       " 0.42648734073609823,\n",
       " 0.49341782659021971,\n",
       " 0.67157031654232813,\n",
       " 0.57368085035796479,\n",
       " 0.57112446151440366,\n",
       " 0.39069230158199375,\n",
       " 0.43304183064412138,\n",
       " 0.64182685663470829,\n",
       " 0.67756074926208587,\n",
       " 0.7573545732610576,\n",
       " 0.59575255102691782,\n",
       " 0.50774020466819259,\n",
       " 0.66111856958283821,\n",
       " 0.69232383329677183,\n",
       " 0.55750391678244549,\n",
       " 0.74409135634277779,\n",
       " 0.67178590397621329,\n",
       " 0.85365853658536583,\n",
       " 0.52465655437025738,\n",
       " 0.79514980586888406,\n",
       " 0.50821381469686866,\n",
       " 0.51937772678025074,\n",
       " 0.82640587189942616,\n",
       " 0.72267882406734119,\n",
       " 0.53421551326441086,\n",
       " 0.58625001515325736,\n",
       " 0.50622449692935212,\n",
       " 0.61773588795222356,\n",
       " 0.46455731707655717,\n",
       " 0.81481481481481477,\n",
       " 0.63560190704854191,\n",
       " 0.64962945366789482,\n",
       " 0.4681182818616979,\n",
       " 0.8529411764705882,\n",
       " 0.72566627307458598,\n",
       " 0.4898271544580422,\n",
       " 0.45317988985998647,\n",
       " 0.48483529767317785,\n",
       " 0.62709616989355021,\n",
       " 0.62285648676883043,\n",
       " 0.5299076686816736,\n",
       " 0.53615640406053511,\n",
       " 0.49411763002229492,\n",
       " 0.9285714285714286,\n",
       " 0.62521802304899232,\n",
       " 0.46398208913731254,\n",
       " 0.62926969233375096,\n",
       " 0.52445308296473836,\n",
       " 0.60963111640425205,\n",
       " 0.55560440484631857,\n",
       " 0.44010802348856026,\n",
       " 0.49970579676904325,\n",
       " 0.36954831360628149,\n",
       " 0.40189734587832715,\n",
       " 0.50688047584351459,\n",
       " 0.62813774523824029,\n",
       " 0.60776851918010988,\n",
       " 0.51594592452221666,\n",
       " 0.57191194974453541,\n",
       " 0.57060924362129972,\n",
       " 0.70772843246166273,\n",
       " 0.42007646873180676,\n",
       " 0.71953146194684792,\n",
       " 0.60016434704501431,\n",
       " 0.50277597777137339,\n",
       " 0.55800847332920911,\n",
       " 0.87126171069178671,\n",
       " 0.62584902449987534,\n",
       " 0.91552303212232122,\n",
       " 0.53162341462555684,\n",
       " 0.65608403947062077,\n",
       " 0.5484781071658853,\n",
       " 0.55429021750600116,\n",
       " 0.78730944319169094,\n",
       " 0.77385655198685077,\n",
       " 0.57978443956140291,\n",
       " 0.83673170434474009,\n",
       " 0.57447684078974892,\n",
       " 0.50458517573538897,\n",
       " 0.65936251425009307,\n",
       " 0.74062480299980771,\n",
       " 0.88214304708182267,\n",
       " 0.63419068837758519,\n",
       " 0.4119551427668261,\n",
       " 0.4300313775017543,\n",
       " 0.52415069718218443,\n",
       " 0.54895805230912664,\n",
       " 0.68648199370146279,\n",
       " 0.54855788356150259,\n",
       " 0.50485153652645021,\n",
       " 0.69670159444211754,\n",
       " 0.58757959894413303,\n",
       " 0.83465819098331018,\n",
       " 0.54933489477634967,\n",
       " 0.53192016431572142,\n",
       " 0.90000000000000002,\n",
       " 0.33654955849354729,\n",
       " 0.46974872245377103,\n",
       " 0.967741935483871,\n",
       " 0.59232531442800596,\n",
       " 0.46512674394180092,\n",
       " 0.79373502096839488,\n",
       " 0.73911254401298765,\n",
       " 0.55763160861763805,\n",
       " 0.60571427949732137,\n",
       " 0.89610514417073817,\n",
       " 0.66742000277499902,\n",
       " 0.91666666666666663,\n",
       " 0.70000624574722348,\n",
       " 0.59414063666013173,\n",
       " 0.4371043338531877,\n",
       " 0.49741939656840939,\n",
       " 0.60382275402774088,\n",
       " 0.77851304360845897,\n",
       " 0.55496955283883087,\n",
       " 0.61042086743720647,\n",
       " 0.564926009986358,\n",
       " 0.65333124131093301,\n",
       " 0.54176780617464271,\n",
       " 0.55155933650878664,\n",
       " 0.58133444144521063,\n",
       " 0.55635141799576504,\n",
       " 0.63437201958295864,\n",
       " 0.76932510795069342,\n",
       " 0.5772811476771863,\n",
       " 0.71756977875915096,\n",
       " 0.56386641088435518,\n",
       " 1.0,\n",
       " 0.38056981092568837,\n",
       " 0.48858979314936318,\n",
       " 0.64858506160325424,\n",
       " 0.54878043350763828,\n",
       " 0.87179487179487181,\n",
       " 0.76380081812851186,\n",
       " 0.46365329211086115,\n",
       " 0.92592592592592593,\n",
       " 0.5468369131411418,\n",
       " 0.56570448605887713,\n",
       " 0.44428454359134473,\n",
       " 0.56049547797678112,\n",
       " 0.62310957359486829,\n",
       " 0.62706460567326527,\n",
       " 0.91488537282199411,\n",
       " 0.74576096615435561,\n",
       " 0.18793136023432644,\n",
       " 0.85242914045231655,\n",
       " 0.47254287380543497,\n",
       " 0.69203966815014462,\n",
       " 0.53456731693690274,\n",
       " 0.52182194799747739,\n",
       " 0.57908119682981463,\n",
       " 0.47762135995510596,\n",
       " 0.51786358268279731,\n",
       " 0.75718333056164699,\n",
       " 0.65377420995116564,\n",
       " 0.55898112212084239,\n",
       " 0.84615384615384615,\n",
       " 0.80250032197961185,\n",
       " 0.74403488739334989,\n",
       " 0.45590445656948986,\n",
       " 0.29921812257253949,\n",
       " 0.5905635794609394,\n",
       " 0.46605348357631476,\n",
       " 0.75253017037316172,\n",
       " 0.56457461626330452,\n",
       " 0.71196576000940393,\n",
       " 0.57830815663884283,\n",
       " 0.60855450885126394,\n",
       " 0.57236663274152433,\n",
       " 0.55701003458728127,\n",
       " 0.65179301253463107,\n",
       " 0.86784695759057096,\n",
       " 0.51574128856303714,\n",
       " 0.66648967375845991,\n",
       " 0.79543993204069552,\n",
       " 0.73226909079993174,\n",
       " 0.62890081505596618,\n",
       " 0.70764004791140001,\n",
       " 0.54909159266091867,\n",
       " 0.63394962509650343,\n",
       " 0.62769465837971028,\n",
       " 0.63579171523973843,\n",
       " 0.69310849160207744,\n",
       " 0.70059852959182745,\n",
       " 0.65252460931163536,\n",
       " 1.0,\n",
       " 0.66511046225032577,\n",
       " 0.7757372793905648,\n",
       " 0.56042725183540443,\n",
       " 0.54492861948227111,\n",
       " 0.65753752799606013,\n",
       " 0.51998163808970654,\n",
       " 0.86677603660370195,\n",
       " 0.47694515324917169,\n",
       " 0.61819619463834374,\n",
       " 0.63221227208421371,\n",
       " 0.58068011980417111,\n",
       " 0.49495471428945059,\n",
       " 0.24675052203424794,\n",
       " 0.75553370645502327,\n",
       " 0.54422704560306612,\n",
       " 0.8571428571428571,\n",
       " 0.52646034457089763,\n",
       " 0.6100143649193247,\n",
       " 0.57593434366053031,\n",
       " 0.55080254646813143,\n",
       " 0.53565105900526044,\n",
       " 0.6904640723158374,\n",
       " 0.62210082679056367,\n",
       " 0.39822813756275194,\n",
       " 0.64554634795006305,\n",
       " 0.52379325650748743,\n",
       " 0.67601986919343993,\n",
       " 0.39666281364407757,\n",
       " 0.47468092770969711,\n",
       " 0.76321400163491393,\n",
       " 0.64901187671176319,\n",
       " 0.65863699552025201,\n",
       " 0.60547578646217926,\n",
       " 0.53203244802782645,\n",
       " 0.52984322053623345,\n",
       " 0.49129972694127133,\n",
       " 0.48104363936470429,\n",
       " 0.53274868488924298,\n",
       " 0.4385023601775081,\n",
       " 0.67407177866821211,\n",
       " 0.76923076923076927,\n",
       " 0.53860738619144399,\n",
       " 0.60207689033828238,\n",
       " 0.94444444444444442,\n",
       " 0.54556675068524574,\n",
       " 0.38193256676489779,\n",
       " 0.51790348277837794,\n",
       " 0.45457771519187473,\n",
       " 0.58505174984732733,\n",
       " 0.41510074798277702,\n",
       " 0.4143940748037796,\n",
       " 0.65622791673339975,\n",
       " 0.63755363926046449,\n",
       " 0.64359761769243473,\n",
       " 0.85950407640901283,\n",
       " 0.4175289580596841,\n",
       " 0.40991952483304922,\n",
       " 0.55207143276178261,\n",
       " 0.52789278393751859,\n",
       " 0.68661424482344802,\n",
       " 0.54099325436343371,\n",
       " 0.86842105263157898,\n",
       " 0.8459948615599211,\n",
       " 0.60179632466124922,\n",
       " 0.711445992067819,\n",
       " 0.45899297929008376,\n",
       " 0.60832871244178632,\n",
       " 0.44315028787389565,\n",
       " 0.50714497800365765,\n",
       " 0.67951800772787241,\n",
       " 0.48754046134748419,\n",
       " 0.4769178959688567,\n",
       " 0.6971377667567582,\n",
       " 0.81818181818181823,\n",
       " 0.49286236573520842,\n",
       " 0.69364963012945791,\n",
       " 0.80681507724849577,\n",
       " 0.34573550109265139,\n",
       " 0.48104472660742315,\n",
       " 0.71087723838768035,\n",
       " 0.55225245779453758,\n",
       " 0.61585262957744602,\n",
       " 0.57059316232362356,\n",
       " 0.65047939753917006,\n",
       " 0.71831121137604681,\n",
       " 0.69038623528392662,\n",
       " 0.5912415568278504,\n",
       " 0.76255292601170988,\n",
       " 0.61085843128974349,\n",
       " 0.96153846153846156,\n",
       " 0.68127577715977516,\n",
       " 0.31425584897544295,\n",
       " 0.53945087038830131,\n",
       " 0.5311217742677572,\n",
       " 0.66795498258953168,\n",
       " 0.56611141061264492,\n",
       " 0.3628221917531923,\n",
       " 0.81223407641495504,\n",
       " 0.62640259554948297,\n",
       " 0.6041724730733824,\n",
       " 0.58645249254233978,\n",
       " 0.54624673047086192,\n",
       " 0.62453233349745174,\n",
       " 0.8571428571428571,\n",
       " 0.66507459335747954,\n",
       " 0.46290849753773167,\n",
       " 0.33771700340104616,\n",
       " 0.79283675688490596,\n",
       " 0.48638417090617792,\n",
       " 0.55685393144123485,\n",
       " 0.54114903778669243,\n",
       " 0.58957570674176307,\n",
       " 0.88056188942846092,\n",
       " 0.58950647610739404,\n",
       " 0.58711231356140481,\n",
       " 0.35924005310331647,\n",
       " 0.77387959469572598,\n",
       " 0.66801447182040308,\n",
       " 0.53908160938390726,\n",
       " 0.75,\n",
       " 0.490070310567644,\n",
       " 0.77064447663681113,\n",
       " 0.63142346558934181,\n",
       " 0.5760538590768256]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 1.0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(gs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predictions)):\n",
    "    if np.isnan(predictions[i]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. ', '. ']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs[419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
