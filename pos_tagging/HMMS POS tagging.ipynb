{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMMS POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import nps_chat\n",
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'now', 'RB'), (u'im', 'PRP'), (u'left', 'VBD'), (u'with', 'IN'), (u'this', 'DT'), (u'gay', 'JJ'), (u'name', 'NN')], [(u':P', 'UH')], ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps_chat.tagged_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'Confidence', u'NN'), (u'in', u'IN'), (u'the', u'DT'), (u'pound', u'NN'), (u'is', u'VBZ'), (u'widely', u'RB'), (u'expected', u'VBN'), (u'to', u'TO'), (u'take', u'VB'), (u'another', u'DT'), (u'sharp', u'JJ'), (u'dive', u'NN'), (u'if', u'IN'), (u'trade', u'NN'), (u'figures', u'NNS'), (u'for', u'IN'), (u'September', u'NNP'), (u',', u','), (u'due', u'JJ'), (u'for', u'IN'), (u'release', u'NN'), (u'tomorrow', u'NN'), (u',', u','), (u'fail', u'VB'), (u'to', u'TO'), (u'show', u'VB'), (u'a', u'DT'), (u'substantial', u'JJ'), (u'improvement', u'NN'), (u'from', u'IN'), (u'July', u'NNP'), (u'and', u'CC'), (u'August', u'NNP'), (u\"'s\", u'POS'), (u'near-record', u'JJ'), (u'deficits', u'NNS'), (u'.', u'.')], [(u'Chancellor', u'NNP'), (u'of', u'IN'), (u'the', u'DT'), (u'Exchequer', u'NNP'), (u'Nigel', u'NNP'), (u'Lawson', u'NNP'), (u\"'s\", u'POS'), (u'restated', u'VBN'), (u'commitment', u'NN'), (u'to', u'TO'), (u'a', u'DT'), (u'firm', u'NN'), (u'monetary', u'JJ'), (u'policy', u'NN'), (u'has', u'VBZ'), (u'helped', u'VBN'), (u'to', u'TO'), (u'prevent', u'VB'), (u'a', u'DT'), (u'freefall', u'NN'), (u'in', u'IN'), (u'sterling', u'NN'), (u'over', u'IN'), (u'the', u'DT'), (u'past', u'JJ'), (u'week', u'NN'), (u'.', u'.')], ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2000.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'The', u'AT'), (u'Fulton', u'NP-TL'), (u'County', u'NN-TL'), (u'Grand', u'JJ-TL'), (u'Jury', u'NN-TL'), (u'said', u'VBD'), (u'Friday', u'NR'), (u'an', u'AT'), (u'investigation', u'NN'), (u'of', u'IN'), (u\"Atlanta's\", u'NP$'), (u'recent', u'JJ'), (u'primary', u'NN'), (u'election', u'NN'), (u'produced', u'VBD'), (u'``', u'``'), (u'no', u'AT'), (u'evidence', u'NN'), (u\"''\", u\"''\"), (u'that', u'CS'), (u'any', u'DTI'), (u'irregularities', u'NNS'), (u'took', u'VBD'), (u'place', u'NN'), (u'.', u'.')], [(u'The', u'AT'), (u'jury', u'NN'), (u'further', u'RBR'), (u'said', u'VBD'), (u'in', u'IN'), (u'term-end', u'NN'), (u'presentments', u'NNS'), (u'that', u'CS'), (u'the', u'AT'), (u'City', u'NN-TL'), (u'Executive', u'JJ-TL'), (u'Committee', u'NN-TL'), (u',', u','), (u'which', u'WDT'), (u'had', u'HVD'), (u'over-all', u'JJ'), (u'charge', u'NN'), (u'of', u'IN'), (u'the', u'AT'), (u'election', u'NN'), (u',', u','), (u'``', u'``'), (u'deserves', u'VBZ'), (u'the', u'AT'), (u'praise', u'NN'), (u'and', u'CC'), (u'thanks', u'NNS'), (u'of', u'IN'), (u'the', u'AT'), (u'City', u'NN-TL'), (u'of', u'IN-TL'), (u'Atlanta', u'NP-TL'), (u\"''\", u\"''\"), (u'for', u'IN'), (u'the', u'AT'), (u'manner', u'NN'), (u'in', u'IN'), (u'which', u'WDT'), (u'the', u'AT'), (u'election', u'NN'), (u'was', u'BEDZ'), (u'conducted', u'VBN'), (u'.', u'.')], ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure is the same, so we take the POS tags(using only the first two char of the POS tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown_word_tags = []\n",
    "for sent in brown.tagged_sents():\n",
    "    brown_word_tags.append((\"START\", \"START\"))\n",
    "    brown_word_tags.extend([(tag[:2], word) for (word, tag) in sent])\n",
    "    brown_word_tags.append((\"END\", \"END\"))\n",
    "    \n",
    "conll_word_tags = []    \n",
    "for sent in conll2000.tagged_sents():\n",
    "    conll_word_tags.append((\"START\", \"START\"))\n",
    "    conll_word_tags.extend([(tag[:2], word) for (word, tag) in sent])\n",
    "    conll_word_tags.append((\"END\", \"END\"))\n",
    "    \n",
    "nps_word_tags = []\n",
    "for sent in nps_chat.tagged_posts():\n",
    "    nps_word_tags.append((\"START\", \"START\"))\n",
    "    nps_word_tags.extend([(tag[:2], word) for (word, tag) in sent])\n",
    "    nps_word_tags.append((\"END\", \"END\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in Brown corpus:  57340\n",
      "Number of instances in CONL2000 corpus:  10567\n",
      "Number of instances in NPS_chat corpus:  10948\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of instances in Brown corpus: \", len(brown.tagged_sents()))\n",
    "print(\"Number of instances in CONL2000 corpus: \", len(nps_chat.tagged_posts()))\n",
    "print(\"Number of instances in NPS_chat corpus: \", len(conll2000.tagged_sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training using Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conditional frequency distribution\n",
    "cfd_tagwords = nltk.ConditionalFreqDist(brown_word_tags)\n",
    "# conditional probability distribution usando MLE\n",
    "cpd_tagwords = nltk.ConditionalProbDist(cfd_tagwords, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown_tags = [tag for (tag, word) in brown_word_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfd_tags= nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n",
    "cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'This',\n",
       " u'has',\n",
       " u'increased',\n",
       " u'the',\n",
       " u'risk',\n",
       " u'of',\n",
       " u'the',\n",
       " u'government',\n",
       " u'being',\n",
       " u'forced',\n",
       " u'to',\n",
       " u'increase',\n",
       " u'base',\n",
       " u'rates',\n",
       " u'to',\n",
       " u'16',\n",
       " u'%',\n",
       " u'from',\n",
       " u'their',\n",
       " u'current',\n",
       " u'15',\n",
       " u'%',\n",
       " u'level',\n",
       " u'to',\n",
       " u'defend',\n",
       " u'the',\n",
       " u'pound',\n",
       " u',',\n",
       " u'economists',\n",
       " u'and',\n",
       " u'foreign',\n",
       " u'exchange',\n",
       " u'market',\n",
       " u'analysts',\n",
       " u'say',\n",
       " u'.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2000.sents()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'DO': 0.0, u'BE': 0.0, u'WD': 0.0, u'WQ': 0.0, u'FW': 0.0, u'IN': 0.0, u'HV': 0.0, u'VB': 0.0, u\"''\": 0.0, u')-': 0.0, u'WR': 0.0, u'JJ': 0.0, u'WP': 0.0, u'DT': 0.0033218181276236437, u',-': 0.0, u'NI': 0.0, u'PP': 0.0, u'RP': 0.0, u'.-': 0.0, u'NN': 0.0, u')': 0.0, u'(': 0.0, u'*': 0.0, u',': 0.0, u'.': 0.0, u'TO': 0.0, u'RB': 0.0, u'NP': 0.0, u'RN': 0.0, u':': 0.0, u'PN': 0.0, u'``': 0.0, u'AB': 0.0, 'END': 0.0, u'CC': 0.0, u'CD': 0.0, u'*-': 0.0, u'AT': 0.0, u'(-': 0.0, u'CS': 0.0, u'NR': 0.0, u'MD': 0.0, u':-': 0.0, u\"'\": 0.0, u'AP': 0.0, u'--': 0.0, u'OD': 0.0, u'UH': 0.0, u'QL': 0.0, u'EX': 0.0}\n",
      "{u'DO': 'START', u'BE': 'START', u'WD': 'START', u'WQ': 'START', u'FW': 'START', u'IN': 'START', u'HV': 'START', u'VB': 'START', u\"''\": 'START', u')-': 'START', u'WR': 'START', u'JJ': 'START', u'WP': 'START', u'DT': 'START', u',-': 'START', u'NI': 'START', u'PP': 'START', u'RP': 'START', u'.-': 'START', u'NN': 'START', u')': 'START', u'(': 'START', u'*': 'START', u',': 'START', u'.': 'START', u'TO': 'START', u'RB': 'START', u'NP': 'START', u'RN': 'START', u':': 'START', u'PN': 'START', u'``': 'START', u'AB': 'START', 'END': 'START', u'CC': 'START', u'CD': 'START', u'*-': 'START', u'AT': 'START', u'(-': 'START', u'CS': 'START', u'NR': 'START', u'MD': 'START', u':-': 'START', u\"'\": 'START', u'AP': 'START', u'--': 'START', u'OD': 'START', u'UH': 'START', u'QL': 'START', u'EX': 'START'}\n"
     ]
    }
   ],
   "source": [
    "distinct_tags = set(brown_tags)\n",
    "\n",
    "#sentence = [\"I\", \"want\", \"to\", \"race\" ]\n",
    "#sentence = [\"I\", \"saw\", \"her\", \"duck\" ]\n",
    "sentence = conll2000.sents()[3]\n",
    "sentlen = len(sentence)\n",
    "\n",
    "viterbi = []\n",
    "backpointer = [ ]\n",
    "\n",
    "# Inicializacion de las variables de viterbi_1 v_s(1)\n",
    "first_viterbi = { }\n",
    "first_backpointer = { }\n",
    "for tag in distinct_tags:\n",
    "    # don't record anything for the START tag\n",
    "    if tag == \"START\": continue\n",
    "    first_viterbi[ tag ] = cpd_tags[\"START\"].prob(tag) * cpd_tagwords[tag].prob( sentence[0] )\n",
    "    first_backpointer[ tag ] = \"START\"\n",
    "\n",
    "print(first_viterbi)\n",
    "print(first_backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'This' current best two-tag sequence: START DT\n"
     ]
    }
   ],
   "source": [
    "viterbi.append(first_viterbi)\n",
    "backpointer.append(first_backpointer)\n",
    "\n",
    "currbest = max(first_viterbi.keys(), key = lambda tag: first_viterbi[ tag ])\n",
    "print( \"Word\", \"'\" + sentence[0] + \"'\", \"current best two-tag sequence:\", \n",
    "      first_backpointer[ currbest], currbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'has' current best two-tag sequence: DT HV\n",
      "Word 'increased' current best two-tag sequence: HV VB\n",
      "Word 'the' current best two-tag sequence: VB AT\n",
      "Word 'risk' current best two-tag sequence: AT NN\n",
      "Word 'of' current best two-tag sequence: NN IN\n",
      "Word 'the' current best two-tag sequence: IN AT\n",
      "Word 'government' current best two-tag sequence: AT NN\n",
      "Word 'being' current best two-tag sequence: NN BE\n",
      "Word 'forced' current best two-tag sequence: BE VB\n",
      "Word 'to' current best two-tag sequence: VB TO\n",
      "Word 'increase' current best two-tag sequence: TO VB\n",
      "Word 'base' current best two-tag sequence: VB NN\n",
      "Word 'rates' current best two-tag sequence: NN NN\n",
      "Word 'to' current best two-tag sequence: NN IN\n",
      "Word '16' current best two-tag sequence: IN CD\n",
      "Word '%' current best two-tag sequence: DO DO\n",
      "Word 'from' current best two-tag sequence: DO DO\n",
      "Word 'their' current best two-tag sequence: DO DO\n",
      "Word 'current' current best two-tag sequence: DO DO\n",
      "Word '15' current best two-tag sequence: DO DO\n",
      "Word '%' current best two-tag sequence: DO DO\n",
      "Word 'level' current best two-tag sequence: DO DO\n",
      "Word 'to' current best two-tag sequence: DO DO\n",
      "Word 'defend' current best two-tag sequence: DO DO\n",
      "Word 'the' current best two-tag sequence: DO DO\n",
      "Word 'pound' current best two-tag sequence: DO DO\n",
      "Word ',' current best two-tag sequence: DO DO\n",
      "Word 'economists' current best two-tag sequence: DO DO\n",
      "Word 'and' current best two-tag sequence: DO DO\n",
      "Word 'foreign' current best two-tag sequence: DO DO\n",
      "Word 'exchange' current best two-tag sequence: DO DO\n",
      "Word 'market' current best two-tag sequence: DO DO\n",
      "Word 'analysts' current best two-tag sequence: DO DO\n",
      "Word 'say' current best two-tag sequence: DO DO\n",
      "Word '.' current best two-tag sequence: DO DO\n",
      "The sentence was: This has increased the risk of the government being forced to increase base rates to 16 % from their current 15 % level to defend the pound , economists and foreign exchange market analysts say . \n",
      "\n",
      "The best tag sequence is: START DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO DO END \n",
      "\n",
      "The probability of the best tag sequence is: 0.0\n"
     ]
    }
   ],
   "source": [
    "for wordindex in range(1, len(sentence)):\n",
    "    this_viterbi = { }\n",
    "    this_backpointer = { }\n",
    "    prev_viterbi = viterbi[-1]\n",
    "    \n",
    "    for tag in distinct_tags:\n",
    "        if tag == \"START\": continue\n",
    "        best_previous = max(prev_viterbi.keys(),\n",
    "                            key = lambda prevtag: \\\n",
    "            prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(tag) * \n",
    "                            cpd_tagwords[tag].prob(sentence[wordindex]))\n",
    "\n",
    "        this_viterbi[ tag ] = prev_viterbi[ best_previous] * \\\n",
    "            cpd_tags[ best_previous ].prob(tag) * cpd_tagwords[ tag].prob(sentence[wordindex])\n",
    "        this_backpointer[ tag ] = best_previous\n",
    "\n",
    "    currbest = max(this_viterbi.keys(), key = lambda tag: this_viterbi[ tag ])\n",
    "    print( \"Word\", \"'\" + sentence[ wordindex] + \"'\", \"current best two-tag sequence:\", \n",
    "          this_backpointer[ currbest], currbest)\n",
    "    viterbi.append(this_viterbi)\n",
    "    backpointer.append(this_backpointer)\n",
    "\n",
    "prev_viterbi = viterbi[-1]\n",
    "best_previous = max(prev_viterbi.keys(),\n",
    "                    key = lambda prevtag: prev_viterbi[ prevtag ] * \n",
    "                    cpd_tags[prevtag].prob(\"END\"))\n",
    "\n",
    "prob_tagsequence = prev_viterbi[ best_previous ] * cpd_tags[ best_previous].prob(\"END\")\n",
    "\n",
    "best_tagsequence = [ \"END\", best_previous ]\n",
    "backpointer.reverse()\n",
    "\n",
    "current_best_tag = best_previous\n",
    "for bp in backpointer:\n",
    "    best_tagsequence.append(bp[current_best_tag])\n",
    "    current_best_tag = bp[current_best_tag]\n",
    "\n",
    "best_tagsequence.reverse()\n",
    "print( \"The sentence was:\", end = \" \")\n",
    "for w in sentence: print( w, end = \" \")\n",
    "print(\"\\n\")\n",
    "print( \"The best tag sequence is:\", end = \" \")\n",
    "for t in best_tagsequence: print (t, end = \" \")\n",
    "print(\"\\n\")\n",
    "print( \"The probability of the best tag sequence is:\", prob_tagsequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it all in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_hmms(tags, cpd_tags, cpd_tagwords, sentence):\n",
    "    #distinct_tags = set(tags)\n",
    "\n",
    "    #sentence = [\"I\", \"want\", \"to\", \"race\" ]\n",
    "    #sentence = [\"I\", \"saw\", \"her\", \"duck\" ]\n",
    "    sentlen = len(sentence)\n",
    "\n",
    "    viterbi = []\n",
    "    backpointer = [ ]\n",
    "\n",
    "    # Inicializacion de las variables de viterbi_1 v_s(1)\n",
    "    first_viterbi = { }\n",
    "    first_backpointer = { }\n",
    "    for tag in distinct_tags:\n",
    "        # don't record anything for the START tag\n",
    "        if tag == \"START\": continue\n",
    "        first_viterbi[ tag ] = cpd_tags[\"START\"].prob(tag) * cpd_tagwords[tag].prob( sentence[0] )\n",
    "        first_backpointer[ tag ] = \"START\"\n",
    "\n",
    "    viterbi.append(first_viterbi)\n",
    "    backpointer.append(first_backpointer)\n",
    "\n",
    "    currbest = max(first_viterbi.keys(), key = lambda tag: first_viterbi[tag])\n",
    "\n",
    "    for wordindex in range(1, len(sentence)):\n",
    "        this_viterbi = {}\n",
    "        this_backpointer = {}\n",
    "        prev_viterbi = viterbi[-1]\n",
    "\n",
    "        for tag in distinct_tags:\n",
    "            if tag == \"START\": continue\n",
    "            best_previous = max(prev_viterbi.keys(),\n",
    "                                key = lambda prevtag: \\\n",
    "                prev_viterbi[ prevtag ] * cpd_tags[prevtag].prob(tag) * \n",
    "                                cpd_tagwords[tag].prob(sentence[wordindex]))\n",
    "\n",
    "            this_viterbi[ tag ] = prev_viterbi[ best_previous] * \\\n",
    "                cpd_tags[ best_previous ].prob(tag) * cpd_tagwords[ tag].prob(sentence[wordindex])\n",
    "            this_backpointer[ tag ] = best_previous\n",
    "\n",
    "        currbest = max(this_viterbi.keys(), key = lambda tag: this_viterbi[ tag ])\n",
    "        viterbi.append(this_viterbi)\n",
    "        backpointer.append(this_backpointer)\n",
    "\n",
    "    prev_viterbi = viterbi[-1]\n",
    "    best_previous = max(prev_viterbi.keys(),\n",
    "                        key = lambda prevtag: prev_viterbi[ prevtag ] * \n",
    "                        cpd_tags[prevtag].prob(\"END\"))\n",
    "\n",
    "    prob_tagsequence = prev_viterbi[ best_previous ] * cpd_tags[ best_previous].prob(\"END\")\n",
    "\n",
    "    best_tagsequence = [ \"END\", best_previous ]\n",
    "    backpointer.reverse()\n",
    "\n",
    "    current_best_tag = best_previous\n",
    "    for bp in backpointer:\n",
    "        best_tagsequence.append(bp[current_best_tag])\n",
    "        current_best_tag = bp[current_best_tag]\n",
    "\n",
    "    best_tagsequence.reverse()\n",
    "    return prob_tagsequence, best_tagsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distinct_tags = set(brown_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i', u\"'ll\", u'thunder', u'clap', u'your', u'ass', u'.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps_chat.posts()[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'The',\n",
       " u'jurors',\n",
       " u'said',\n",
       " u'they',\n",
       " u'realize',\n",
       " u'``',\n",
       " u'a',\n",
       " u'proportionate',\n",
       " u'distribution',\n",
       " u'of',\n",
       " u'these',\n",
       " u'funds',\n",
       " u'might',\n",
       " u'disable',\n",
       " u'this',\n",
       " u'program',\n",
       " u'in',\n",
       " u'our',\n",
       " u'less',\n",
       " u'populous',\n",
       " u'counties',\n",
       " u\"''\",\n",
       " u'.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.sents()[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " ['START',\n",
       "  u'NN',\n",
       "  u'IN',\n",
       "  u'AT',\n",
       "  u'NN',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  u'BE',\n",
       "  'END'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hmms(distinct_tags, cpd_tags, cpd_tagwords, conll2000.sents()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.829128179255946e-69,\n",
       " ['START',\n",
       "  u'AT',\n",
       "  u'NN',\n",
       "  u'VB',\n",
       "  u'PP',\n",
       "  u'VB',\n",
       "  u'``',\n",
       "  u'AT',\n",
       "  u'JJ',\n",
       "  u'NN',\n",
       "  u'IN',\n",
       "  u'DT',\n",
       "  u'NN',\n",
       "  u'MD',\n",
       "  u'VB',\n",
       "  u'DT',\n",
       "  u'NN',\n",
       "  u'IN',\n",
       "  u'PP',\n",
       "  u'QL',\n",
       "  u'JJ',\n",
       "  u'NN',\n",
       "  u\"''\",\n",
       "  u'.',\n",
       "  'END'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hmms(distinct_tags, cpd_tags, cpd_tagwords, brown.sents()[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'now', 'RB'), (u'im', 'PRP'), (u'left', 'VBD'), (u'with', 'IN'), (u'this', 'DT'), (u'gay', 'JJ'), (u'name', 'NN')], [(u':P', 'UH')], ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps_chat.ta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training and Testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Corpora model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
